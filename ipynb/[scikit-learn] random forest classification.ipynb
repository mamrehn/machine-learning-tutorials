{
 "metadata": {
  "name": "",
  "signature": "sha256:0c3e7e2ef9c56afa7d4b1b96856b6b6eaf4c01287bc75f71dcadb770ae80ff2f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Random Forest Classification\n",
      "\n",
      "Use the [Random Forest](http://scikit-learn.org/dev/modules/generated/sklearn.ensemble.RandomForestClassifier.html) implementation of scikit-learn to perform a 10-fold cross-validation on inbalanced data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeCV(data):\n",
      "    # http://scikit-learn.org/dev/modules/classes.html#module-sklearn.cross_validation\n",
      "    from sklearn import ensemble, cross_validation\n",
      "    clf = ensemble.RandomForestClassifier(n_estimators=1000, n_jobs=5, verbose=0, compute_importances=None)\n",
      "    # http://randomforests.wordpress.com/2014/02/02/basics-of-k-fold-cross-validation-and-gridsearchcv-in-scikit-learn/\n",
      "    res = cross_validation.cross_val_score(clf, data.data, data.target, cv=10, n_jobs = 5)\n",
      "    print(res)\n",
      "\n",
      "def dtime_to_seconds(dtime):\n",
      "    return dtime.seconds + (dtime.microseconds * 1e-6)\n",
      "\n",
      "def bench(func, data, n=10):\n",
      "    assert n > 2\n",
      "    score = np.inf\n",
      "    try:\n",
      "        time = []\n",
      "        for i in range(n):\n",
      "            score, t = func(*data)\n",
      "            time.append(dtime_to_seconds(t))\n",
      "        # remove extremal values\n",
      "        time.pop(np.argmax(time))\n",
      "        time.pop(np.argmin(time))\n",
      "    except Exception as detail:\n",
      "        print('%s error in function %s: ', (repr(detail), func))\n",
      "        time = []\n",
      "    return score, np.array(time)\n",
      "\n",
      "def bench_skl(X, y, T, valid):\n",
      "    from sklearn import ensemble #, linear_model\n",
      "    #from sklearn.utils import safe_asarray\n",
      "    start = datetime.now()\n",
      "    \n",
      "    # balance the dataset\n",
      "    # https://github.com/scikit-learn/scikit-learn/blob/8dab222cfe894126dfb67832da2f4e871b87bce7/sklearn/preprocessing/_weights.py\n",
      "    y = np.searchsorted(np.unique(y), y)\n",
      "    class_weight_bins = np.bincount(y)\n",
      "    # from class weights to sample weights\n",
      "    sample_weights = 1. / class_weight_bins.take(y)\n",
      "    sample_weights *= class_weight_bins.min()\n",
      "    \n",
      "    \n",
      "    # http://scikit-learn.org/stable/modules/classes.html\n",
      "    clf = ensemble.RandomForestClassifier(n_estimators=1000, n_jobs=5, verbose=0, compute_importances=None)\n",
      "    #clf = linear_model.ElasticNet(alpha=0.5, l1_ratio=0.5)\n",
      "    #clf = linear_model.LogisticRegression()\n",
      "    #clf = neighbors.NeighborsClassifier(n_neighbors=n_neighbors, algorithm='brute_inplace')\n",
      "    #clf = skl_cluster.KMeans(k=n_components, n_init=1)\n",
      "    #...\n",
      "    clf.fit(X, y, sample_weights)\n",
      "\n",
      "    ## Regression\n",
      "    # pred = clf.predict(T)\n",
      "    # delta = datetime.now() - start\n",
      "    # mse = np.linalg.norm(pred - valid, 2) ** 2\n",
      "    # return mse, delta\n",
      "\n",
      "    # Classification\n",
      "    score = np.mean(clf.predict(T) == valid)\n",
      "    return score, datetime.now() - start\n",
      "\n",
      "def computeAverageFromNRuns(data, num_tries, TH):\n",
      "    sample_range = np.random.random_sample(size=iris.target.shape[0])\n",
      "    X = np.array([(iris.data[i,]) for i in range(len(iris.target)) if sample_range[i] >= TH])\n",
      "    Y = np.array([(iris.target[i,]) for i in range(len(iris.target)) if sample_range[i] >= TH])\n",
      "    T = np.array([(iris.data[i,]) for i in range(len(iris.target)) if sample_range[i] < TH])\n",
      "    valid = np.array([(iris.target[i,]) for i in range(len(iris.target)) if sample_range[i] < TH])\n",
      "\n",
      "    #X, T, y, valid = cross_validation.train_test_split(iris.data, iris.target, test_size=0.9, random_state=0)\n",
      "\n",
      "    num_tries = 25\n",
      "    score, times = bench(bench_skl, (X,Y,T,valid), num_tries)\n",
      "    print('Tries:', num_tries, 'Score:', score, 'Time:', np.mean(times), '(mean)', np.median(times), '(median)')\n",
      "\n",
      "from sklearn import datasets\n",
      "import numpy as np\n",
      "from datetime import datetime\n",
      "#from sklearn import cross_validation\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "computeCV(iris)\n",
      "\n",
      "runs = 25\n",
      "TH = 0.9\n",
      "\n",
      "computeAverageFromNRuns(iris, runs, TH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.          0.93333333  1.          0.93333333  0.93333333  0.93333333\n",
        "  0.86666667  1.          1.          1.        ]\n",
        "('Tries:', 25, 'Score:', 0.94656488549618323, 'Time:', 0.58613043478260873, '(mean)', 0.57999999999999996, '(median)')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}